{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np \nimport pandas as pd \nfrom sklearn import cross_validation, grid_search, linear_model, metrics, pipeline, preprocessing",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Submissions are evaluated one the Root Mean Squared Logarithmic Error (RMSLE) so lets define it. Also we are using common mean absolute error**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def rmsle(y, y_):\n    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))\n    calc = (log1 - log2) ** 2\n    return np.sqrt(np.mean(calc))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data = pd.read_csv(\"../input/train.csv\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data.head(3)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data.isnull().values.any()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data.datetime = data.datetime.apply(pd.to_datetime)\ndata['month'] = data.datetime.apply(lambda x : x.month)\ndata['hour'] = data.datetime.apply(lambda x : x.hour)\ndata.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_data = data.iloc[:-1000, :]\ntest_data = data.iloc[-1000:, :]\nprint(data.shape, train_data.shape, test_data.shape)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_labels = train_data['count'].values\ntrain_data = train_data.drop(['datetime', 'count', 'casual', 'registered'], axis = 1)\ntest_labels = test_data['count'].values\ntest_data = test_data.drop(['datetime', 'count', 'casual', 'registered'], axis = 1)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "binary_data_columns = ['holiday', 'workingday']\nbinary_data_indices = np.array([(column in binary_data_columns) for column in train_data.columns], dtype = bool)\n\ncategorical_data_columns = ['season', 'weather', 'month'] \ncategorical_data_indices = np.array([(column in categorical_data_columns) for column in train_data.columns], dtype = bool)\n\nnumeric_data_columns = ['temp', 'atemp', 'humidity', 'windspeed', 'hour']\nnumeric_data_indices = np.array([(column in numeric_data_columns) for column in train_data.columns], dtype = bool)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "transformer_list = [        \n            #binary\n            ('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n                    \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices])),\n                ('scaling', preprocessing.StandardScaler(with_mean = 0))            \n                        ])),\n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices])),\n                ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown = 'ignore'))            \n                        ])),\n        ]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**SGDRegressor**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "regressor = linear_model.Lasso(max_iter = 2000)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "estimator = pipeline.Pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list=transformer_list)),\n    ('model_fitting', regressor)\n    ]\n)\n\nestimator.fit(train_data, train_labels)\npredicted = estimator.predict(test_data)\n\nprint(\"RMSLE: \", rmsle(test_labels, predicted))\nprint(\"MAE: \",  metrics.mean_absolute_error(test_labels, predicted))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Lets try out to filter best model parameters**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "parameters_grid = {\n    'model_fitting__alpha' : [0.1, 1, 2, 3, 4, 10, 30]\n}",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "rmsle_scorer = metrics.make_scorer(rmsle, greater_is_better=False)\ngrid_cv = grid_search.GridSearchCV(estimator, parameters_grid, scoring = rmsle_scorer, cv = 4)\ngrid_cv.fit(train_data, train_labels)\n\npredicted = grid_cv.best_estimator_.predict(test_data)\n\nprint(\"RMSLE: \", rmsle(test_labels, predicted))\n#print(\"MAE: \",  metrics.mean_absolute_error(test_labels, predicted))\nprint(\"Best params: \", grid_cv.best_params_)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "estimator.get_params().keys()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(random_state = 0, max_depth = 20, n_estimators = 150)\nestimator = pipeline.Pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = transformer_list)),\n    ('model_fitting', regressor)\n    ]\n)\nestimator.fit(train_data, train_labels)\n#metrics.mean_absolute_error(test_labels, estimator.predict(test_data))\nprint(\"RMSLE: \", rmsle(test_labels, estimator.predict(test_data)))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#estimator.get_params().keys()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "##parameters_grid = {\n##    'model_fitting__n_estimators' : [70, 100, 130],\n##    'model_fitting__max_features' : [3, 4, 5, 6],\n##}\n##\n##grid_cv = grid_search.GridSearchCV(estimator, parameters_grid, scoring = 'neg_mean_absolute_error', cv = 3)\n##grid_cv.fit(train_data, train_labels)\n##\n##print(-grid_cv.best_score_)\n##print(grid_cv.best_params_)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pylab inline\npylab.figure(figsize=(8, 3))\n\npylab.subplot(1,2,1)\npylab.grid(True)\npylab.xlim(-100,1100)\npylab.ylim(-100,1100)\npylab.scatter(train_labels, grid_cv.best_estimator_.predict(train_data), alpha=0.5, color = 'red')\npylab.scatter(test_labels, grid_cv.best_estimator_.predict(test_data), alpha=0.5, color = 'blue')\npylab.title('linear model')\n\npylab.subplot(1,2,2)\npylab.grid(True)\npylab.xlim(-100,1100)\npylab.ylim(-100,1100)\npylab.scatter(train_labels, estimator.predict(train_data), alpha=0.5, color = 'red')\npylab.scatter(test_labels, estimator.predict(test_data), alpha=0.5, color = 'blue')\npylab.title('random forest model')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import GradientBoostingRegressor\n\ngbr = GradientBoostingRegressor(n_estimators=200, learning_rate=0.9, max_depth = 4)\n\nestimator = pipeline.Pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = transformer_list)),\n    ('model_fitting', gbr)\n    ]\n)\nestimator.fit(train_data, train_labels)\n#metrics.mean_absolute_error(test_labels, estimator.predict(test_data))\nprint(\"RMSLE: \", rmsle(test_labels, estimator.predict(test_data)))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pylab inline\npylab.figure(figsize=(8, 3))\n\npylab.subplot(1,2,1)\npylab.grid(True)\npylab.xlim(-100,1100)\npylab.ylim(-100,1100)\npylab.scatter(train_labels, grid_cv.best_estimator_.predict(train_data), alpha=0.5, color = 'red')\npylab.scatter(test_labels, grid_cv.best_estimator_.predict(test_data), alpha=0.5, color = 'blue')\npylab.title('linear model')\n\npylab.subplot(1,2,2)\npylab.grid(True)\npylab.xlim(-100,1100)\npylab.ylim(-100,1100)\npylab.scatter(train_labels, estimator.predict(train_data), alpha=0.5, color = 'red')\npylab.scatter(test_labels, estimator.predict(test_data), alpha=0.5, color = 'blue')\npylab.title('gbr model')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "real_test_data = pd.read_csv(\"../input/test.csv\")\nreal_test_data_ids = real_test_data[\"datetime\"]\nreal_test_data.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "real_test_data.datetime = real_test_data.datetime.apply(pd.to_datetime)\nreal_test_data['month'] = real_test_data.datetime.apply(lambda x : x.month)\nreal_test_data['hour'] = real_test_data.datetime.apply(lambda x : x.hour)\nreal_test_data.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "real_test_data = real_test_data.drop(['datetime'], axis = 1)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "real_test_predictions = estimator.predict(real_test_data)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "real_test_predictions.min()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "submission = pd.DataFrame({\n        \"datetime\": real_test_data_ids,\n        \"count\": [max(0, x) for x in real_test_predictions]\n    })\nsubmission.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "submission.to_csv('bike_predictions.csv', index=False)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}